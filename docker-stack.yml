version: '3.8'

# AI Agent Platform - Production Docker Swarm Stack
# Optimized for high availability, scalability, and monitoring

networks:
  ai-platform-network:
    driver: overlay
    attachable: true
  traefik-public:
    external: true

volumes:
  # Database volumes
  neo4j_data:
    driver: local
  neo4j_logs:
    driver: local
  postgres_data:
    driver: local
  redis_data:
    driver: local
  minio_data:
    driver: local
  
  # Milvus volumes
  milvus_etcd:
    driver: local
  milvus_minio:
    driver: local
  milvus_data:
    driver: local
  
  # Application volumes
  graphrag_cache:
    driver: local
  agent_logs:
    driver: local
  api_logs:
    driver: local
  
  # Pulsar volumes
  pulsar_data:
    driver: local
  pulsar_conf:
    driver: local

# Secrets for sensitive data
secrets:
  neo4j_password:
    external: true
  postgres_password:
    external: true
  redis_password:
    external: true
  jwt_secret:
    external: true
  openai_api_key:
    external: true

configs:
  prometheus_config:
    external: true
  grafana_dashboard_config:
    external: true
  nginx_config:
    external: true

services:
  # ================================
  # VECTOR DATABASE - MILVUS STACK
  # ================================
  
  # Milvus dependencies
  etcd:
    image: quay.io/coreos/etcd:v3.5.0
    hostname: etcd
    networks:
      - ai-platform-network
    environment:
      - ETCD_AUTO_COMPACTION_MODE=revision
      - ETCD_AUTO_COMPACTION_RETENTION=1000
      - ETCD_QUOTA_BACKEND_BYTES=4294967296
      - ETCD_SNAPSHOT_COUNT=50000
    volumes:
      - milvus_etcd:/etcd
    command: etcd -advertise-client-urls=http://127.0.0.1:2379 -listen-client-urls http://0.0.0.0:2379 --data-dir /etcd
    deploy:
      replicas: 1
      resources:
        limits:
          memory: 1G
          cpus: '0.5'
        reservations:
          memory: 512M
          cpus: '0.25'
      restart_policy:
        condition: on-failure
        delay: 10s

  minio:
    image: minio/minio:RELEASE.2023-03-20T20-16-18Z
    hostname: minio
    networks:
      - ai-platform-network
    environment:
      MINIO_ACCESS_KEY: minioadmin
      MINIO_SECRET_KEY: minioadmin
    ports:
      - "9001:9001"
      - "9000:9000"
    volumes:
      - milvus_minio:/minio_data
    command: minio server /minio_data --console-address ":9001"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3
    deploy:
      replicas: 1
      resources:
        limits:
          memory: 2G
          cpus: '1.0'
        reservations:
          memory: 1G
          cpus: '0.5'

  # Milvus components
  milvus-standalone:
    image: milvusdb/milvus:v2.3.3
    hostname: milvus-standalone
    networks:
      - ai-platform-network
    command: ["milvus", "run", "standalone"]
    environment:
      ETCD_ENDPOINTS: etcd:2379
      MINIO_ADDRESS: minio:9000
    volumes:
      - milvus_data:/var/lib/milvus
    ports:
      - "19530:19530"
      - "9091:9091"
    depends_on:
      - "etcd"
      - "minio"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9091/healthz"]
      interval: 30s
      timeout: 20s
      retries: 5
    deploy:
      replicas: 1
      resources:
        limits:
          memory: 8G
          cpus: '4.0'
        reservations:
          memory: 4G
          cpus: '2.0'
      restart_policy:
        condition: on-failure
        delay: 30s

  # ================================
  # GRAPH DATABASE - NEO4J
  # ================================
  
  neo4j:
    image: neo4j:5.15-community
    hostname: neo4j
    networks:
      - ai-platform-network
    environment:
      - NEO4J_AUTH=neo4j/development
      - NEO4J_PLUGINS=["apoc", "graph-data-science", "n10s"]
      - NEO4J_dbms_security_procedures_unrestricted=apoc.*,gds.*,n10s.*
      - NEO4J_dbms_security_procedures_allowlist=apoc.*,gds.*,n10s.*
      - NEO4J_apoc_export_file_enabled=true
      - NEO4J_apoc_import_file_enabled=true
      - NEO4J_apoc_import_file_use__neo4j__config=true
      - NEO4J_dbms_memory_heap_initial__size=2G
      - NEO4J_dbms_memory_heap_max__size=4G
      - NEO4J_dbms_memory_pagecache_size=2G
      - NEO4J_dbms_connector_bolt_listen__address=0.0.0.0:7687
      - NEO4J_dbms_connector_http_listen__address=0.0.0.0:7474
      - NEO4J_dbms_logs_query_enabled=INFO
    ports:
      - "7474:7474"
      - "7687:7687"
    volumes:
      - neo4j_data:/data
      - neo4j_logs:/logs
      - ./infrastructure/neo4j/plugins:/plugins
      - ./infrastructure/neo4j/import:/var/lib/neo4j/import
    healthcheck:
      test: ["CMD", "cypher-shell", "-u", "neo4j", "-p", "development", "RETURN 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 40s
    deploy:
      replicas: 1
      placement:
        constraints:
          - node.labels.database == true
      resources:
        limits:
          memory: 6G
          cpus: '3.0'
        reservations:
          memory: 3G
          cpus: '1.5'
      restart_policy:
        condition: on-failure
        delay: 30s

  # ================================
  # RELATIONAL DATABASE - POSTGRESQL
  # ================================
  
  postgres:
    image: postgres:16-alpine
    hostname: postgres
    networks:
      - ai-platform-network
    environment:
      - POSTGRES_DB=aiplatform
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=development
      - PGDATA=/var/lib/postgresql/data/pgdata
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./infrastructure/postgres/init:/docker-entrypoint-initdb.d
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres -d aiplatform"]
      interval: 10s
      timeout: 5s
      retries: 5
    deploy:
      replicas: 1
      resources:
        limits:
          memory: 2G
          cpus: '1.0'
        reservations:
          memory: 1G
          cpus: '0.5'
      restart_policy:
        condition: on-failure

  # ================================
  # CACHE - REDIS
  # ================================
  
  redis:
    image: redis:7.2-alpine
    hostname: redis
    networks:
      - ai-platform-network
    command: redis-server --appendonly yes --maxmemory 1gb --maxmemory-policy allkeys-lru
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5
    deploy:
      replicas: 1
      resources:
        limits:
          memory: 1.5G
          cpus: '1.0'
        reservations:
          memory: 1G
          cpus: '0.5'

  # ================================
  # MESSAGE BROKER - PULSAR
  # ================================
  
  pulsar:
    image: apachepulsar/pulsar:3.1.1
    hostname: pulsar
    networks:
      - ai-platform-network
    command: bin/pulsar standalone
    environment:
      - PULSAR_MEM=-Xms2g -Xmx2g -XX:MaxDirectMemorySize=2g
      - PULSAR_LOG_LEVEL=info
    ports:
      - "6650:6650"   # Pulsar broker port
      - "8080:8080"   # Pulsar admin port
    volumes:
      - pulsar_data:/pulsar/data
      - pulsar_conf:/pulsar/conf
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/admin/v2/namespaces/public"]
      interval: 30s
      timeout: 10s
      retries: 5
    deploy:
      replicas: 1
      resources:
        limits:
          memory: 4G
          cpus: '2.0'
        reservations:
          memory: 2G
          cpus: '1.0'
      restart_policy:
        condition: on-failure
        delay: 30s
        max_attempts: 3

  # ================================
  # REVERSE PROXY & LOAD BALANCER
  # ================================
  
  traefik:
    image: traefik:v3.0
    command:
      - --api.dashboard=true
      - --entrypoints.web.address=:80
      - --entrypoints.websecure.address=:443
      - --providers.docker=true
      - --providers.docker.swarmmode=true
      - --providers.docker.exposedbydefault=false
      - --certificatesresolvers.le.acme.email=${ACME_EMAIL}
      - --certificatesresolvers.le.acme.storage=/certificates/acme.json
      - --certificatesresolvers.le.acme.tlschallenge=true
      - --metrics.prometheus=true
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - traefik_certificates:/certificates
    networks:
      - traefik-public
      - ai-platform-network
    deploy:
      placement:
        constraints:
          - node.role == manager
      labels:
        - traefik.enable=true
        - traefik.http.routers.traefik-dashboard.rule=Host(`traefik.${DOMAIN_NAME}`)
        - traefik.http.routers.traefik-dashboard.tls.certresolver=le
        - traefik.http.services.traefik-dashboard.loadbalancer.server.port=8080

  # ================================
  # APPLICATION SERVICES
  # ================================
  
  # Backend API
  backend:
    image: ${REGISTRY:-ghcr.io}/${IMAGE_NAME}/backend:${IMAGE_TAG:-latest}
    networks:
      - ai-platform-network
      - traefik-public
    environment:
      - ENVIRONMENT=production
      - DATABASE_URL=postgresql://postgres:${POSTGRES_PASSWORD}@postgres:5432/aiplatform
      - REDIS_URL=redis://:${REDIS_PASSWORD}@redis:6379
      - NEO4J_URI=bolt://neo4j:7687
      - NEO4J_USER=neo4j
      - NEO4J_PASSWORD=${NEO4J_PASSWORD}
      - MILVUS_HOST=milvus-standalone
      - MILVUS_PORT=19530
      - JWT_SECRET_KEY=${JWT_SECRET}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
    secrets:
      - postgres_password
      - redis_password
      - neo4j_password
      - jwt_secret
      - openai_api_key
    volumes:
      - graphrag_cache:/app/graphrag_cache
      - agent_logs:/app/logs
    deploy:
      replicas: 4
      update_config:
        parallelism: 2
        delay: 10s
        failure_action: rollback
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
      labels:
        - traefik.enable=true
        - traefik.http.routers.backend.rule=Host(`api.${DOMAIN_NAME}`)
        - traefik.http.routers.backend.tls.certresolver=le
        - traefik.http.services.backend.loadbalancer.server.port=8000
        - traefik.http.routers.backend.middlewares=backend-ratelimit
        - traefik.http.middlewares.backend-ratelimit.ratelimit.burst=100
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Frontend Application
  frontend:
    image: ${REGISTRY:-ghcr.io}/${IMAGE_NAME}/frontend:${IMAGE_TAG:-latest}
    networks:
      - ai-platform-network
      - traefik-public
    environment:
      - NODE_ENV=production
      - NUXT_PUBLIC_API_BASE=${API_BASE_URL}
      - NUXT_PUBLIC_WS_URL=${WS_BASE_URL}
    deploy:
      replicas: 3
      update_config:
        parallelism: 1
        delay: 10s
        failure_action: rollback
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M
      labels:
        - traefik.enable=true
        - traefik.http.routers.frontend.rule=Host(`${DOMAIN_NAME}`)
        - traefik.http.routers.frontend.tls.certresolver=le
        - traefik.http.services.frontend.loadbalancer.server.port=3000
        - traefik.http.routers.frontend.middlewares=frontend-compress
        - traefik.http.middlewares.frontend-compress.compress=true
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000"]
      interval: 30s
      timeout: 10s
      retries: 3

  # ================================
  # REVERSE PROXY - NGINX
  # ================================
  
  nginx:
    image: nginx:1.25-alpine
    hostname: nginx
    networks:
      - ai-platform-network
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./infrastructure/nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./infrastructure/nginx/ssl:/etc/nginx/ssl:ro
    depends_on:
      - frontend
      - backend
    healthcheck:
      test: ["CMD", "nginx", "-t"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      replicas: 1
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
        reservations:
          memory: 256M
          cpus: '0.25'

  # ================================
  # MONITORING & OBSERVABILITY
  # ================================
  
  # Prometheus
  prometheus:
    image: prom/prometheus:v2.47.0
    hostname: prometheus
    networks:
      - ai-platform-network
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=15d'
      - '--web.enable-lifecycle'
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./monitoring/prometheus/rules:/etc/prometheus/rules:ro
    deploy:
      replicas: 1
      resources:
        limits:
          memory: 2G
          cpus: '1.0'
        reservations:
          memory: 1G
          cpus: '0.5'

  # Grafana
  grafana:
    image: grafana/grafana:10.1.0
    hostname: grafana
    networks:
      - ai-platform-network
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=development
      - GF_USERS_ALLOW_SIGN_UP=false
    ports:
      - "3001:3000"
    volumes:
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning:ro
      - ./monitoring/grafana/dashboards:/var/lib/grafana/dashboards:ro
    depends_on:
      - prometheus
    deploy:
      replicas: 1
      resources:
        limits:
          memory: 1G
          cpus: '0.5'
        reservations:
          memory: 512M
          cpus: '0.25'

  # ================================
  # UTILITY SERVICES
  # ================================
  
  # Health checker service
  healthchecker:
    image: curlimages/curl:8.3.0
    networks:
      - ai-platform-network
    command: |
      sh -c '
        while true; do
          echo "=== Health Check $$(date) ==="
          echo "Neo4j: $$(curl -s -o /dev/null -w "%{http_code}" http://neo4j:7474)"
          echo "Milvus: $$(curl -s -o /dev/null -w "%{http_code}" http://milvus-standalone:9091/healthz)"
          echo "Postgres: $$(if nc -z postgres 5432; then echo "200"; else echo "000"; fi)"
          echo "Redis: $$(if nc -z redis 6379; then echo "200"; else echo "000"; fi)"
          echo "Pulsar: $$(curl -s -o /dev/null -w "%{http_code}" http://pulsar:8080/admin/v2/namespaces/public)"
          echo "Backend: $$(curl -s -o /dev/null -w "%{http_code}" http://backend:8000/health)"
          echo "Frontend: $$(curl -s -o /dev/null -w "%{http_code}" http://frontend:3000)"
          sleep 30
        done
      '
    deploy:
      replicas: 1
      resources:
        limits:
          memory: 64M
          cpus: '0.1'
      restart_policy:
        condition: on-failure

# ================================
# DEPLOYMENT CONFIGURATION
# ================================

  # Node Exporter
  node-exporter:
    image: prom/node-exporter:v1.6.1
    networks:
      - ai-platform-network
    command:
      - '--path.rootfs=/host'
      - '--path.procfs=/host/proc'
      - '--path.sysfs=/host/sys'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
    volumes:
      - '/:/host:ro,rslave'
    deploy:
      mode: global
      restart_policy:
        condition: on-failure
      resources:
        limits:
          cpus: '0.2'
          memory: 128M

volumes:
  traefik_certificates: